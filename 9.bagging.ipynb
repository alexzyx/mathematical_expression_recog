{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU0 Memory: 10515MB\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "\n",
    "nvmlInit()\n",
    "vram = nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(0)).free/1024.**2\n",
    "print('GPU0 Memory: %dMB' % vram)\n",
    "if vram < 8000:\n",
    "    raise Exception('GPU Memory too low')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model1 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# 所有待识别字符\n",
    "CHAR_VECTOR = \"0123456789+-*()=a\"\n",
    "letters = [letter for letter in CHAR_VECTOR]\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "\n",
    "def get_model(img_w, img_h, num_classes, training):\n",
    "    input_shape = (img_w, img_h, 1)  # (128, 64, 1)\n",
    "\n",
    "    # Make Networkw\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32') # (None, 128, 64, 1)\n",
    "\n",
    "    # Convolution layer (VGG)\n",
    "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 128, 64, 64)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)\n",
    "#     inner = Dropout(0.2)(inner)\n",
    "\n",
    "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 32, 128)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)\n",
    "#     inner = Dropout(0.2)(inner)\n",
    "\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  # (None, 32, 8, 256)\n",
    "#     inner = Dropout(0.2)(inner)\n",
    "\n",
    "#     inner = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 512)\n",
    "#     inner = BatchNormalization()(inner)\n",
    "#     inner = Activation('relu')(inner)\n",
    "#     inner = Conv2D(512, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)\n",
    "#     inner = BatchNormalization()(inner)\n",
    "#     inner = Activation('relu')(inner)\n",
    "#     inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)\n",
    "#     inner = Dropout(0.2)(inner)\n",
    "\n",
    "    inner = Conv2D(256, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "\n",
    "    # CNN to RNN\n",
    "    inner = Reshape(target_shape=((32, 2048)), name='reshape')(inner)  # (None, 32, 2048)\n",
    "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
    "\n",
    "    # RNN layer\n",
    "    lstm_1 = GRU(256, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)\n",
    "    lstm_1b = GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
    "    lstm1_merged = add([lstm_1, lstm_1b])  # (None, 32, 512)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    lstm_2 = GRU(256, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    lstm_2b = GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    lstm2_merged = concatenate([lstm_2, lstm_2b])  # (None, 32, 1024)\n",
    "    lstm2_merged = Dropout(0.2)(lstm2_merged)\n",
    "#     lstm_merged = BatchNormalization()(lstm2_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(num_classes, kernel_initializer='he_normal', name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32') # (None ,8)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "\n",
    "    # Keras doesn't currently support loss funcs with extra parameters so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "rootpath = 'G:/my_code/python/mathematical_expression_recognition/Mathematical_Expression_Recognition_train/'\n",
    "\n",
    "img_w, img_h = 128, 64\n",
    "batch_size = 256\n",
    "downsample_factor = 4\n",
    "max_text_len = 12\n",
    "num_classes = len(letters) + 1\n",
    "print(num_classes)\n",
    "width, height, n_len, n_class = 128, 32, 11, len(letters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2(width, height, n_class, n_len):\n",
    "    rnn_size = 128\n",
    "\n",
    "    input_tensor = Input((width, height, 1))# (128,64,1)\n",
    "    x = input_tensor\n",
    "    \n",
    "    # VGG16 的结构\n",
    "    # 1\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # x = Dropout(0.2)(x) # 模型有过拟合的倾向，加入dropout层\n",
    "    # 2\n",
    "    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # x = Dropout(0.2)(x) # 模型有过拟合的倾向，加入dropout层\n",
    "    # 3\n",
    "    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # x = Dropout(0.2)(x) # 模型有过拟合的倾向，加入dropout层\n",
    "\n",
    "    # CNN to RNN\n",
    "    conv_shape = x.get_shape()\n",
    "    x = Reshape(target_shape=(int(conv_shape[1]), int(conv_shape[2]*conv_shape[3])))(x) #  Flatten\n",
    "\n",
    "    x = Dense(256, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # RNN layer\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(x)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', \n",
    "                 name='gru1_b')(x)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru1_merged = BatchNormalization()(gru1_merged)\n",
    "\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', \n",
    "                 name='gru2_b')(gru1_merged)\n",
    "    x = concatenate([gru_2, gru_2b])\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(n_class, kernel_initializer='he_normal', activation='softmax')(x)\n",
    "    # 预测\n",
    "    base_model = Model(input=input_tensor, output=x)\n",
    "    \n",
    "    return  base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3(width, height, n_class, n_len):\n",
    "    rnn_size = 128\n",
    "\n",
    "    input_tensor = Input((width, height, 1))# (128,64,1)\n",
    "    x = input_tensor\n",
    "    \n",
    "    # VGG16 的结构\n",
    "    # 1\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # x = Dropout(0.2)(x) # 模型有过拟合的倾向，加入dropout层\n",
    "    # 2\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # x = Dropout(0.2)(x) # 模型有过拟合的倾向，加入dropout层\n",
    "    # 3\n",
    "    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(x) # 加入 , padding='same'\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # x = Dropout(0.2)(x) # 模型有过拟合的倾向，加入dropout层\n",
    "\n",
    "    # CNN to RNN\n",
    "    conv_shape = x.get_shape()\n",
    "    x = Reshape(target_shape=(int(conv_shape[1]), int(conv_shape[2]*conv_shape[3])))(x) #  Flatten\n",
    "\n",
    "    x = Dense(128, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # RNN layer\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(x)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', \n",
    "                 name='gru1_b')(x)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru1_merged = BatchNormalization()(gru1_merged)\n",
    "\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', \n",
    "                 name='gru2_b')(gru1_merged)\n",
    "    x = concatenate([gru_2, gru_2b])\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(n_class, kernel_initializer='he_normal', activation='softmax')(x)\n",
    "    # 预测\n",
    "    base_model = Model(input=input_tensor, output=x)\n",
    "    \n",
    "    return  base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1*(8-1)', '1']\n",
      "7\n",
      "1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "test_str='1*(8-1)=1'\n",
    "aaa = test_str.split('=')\n",
    "print(aaa)\n",
    "print(eval(aaa[0]))\n",
    "print(eval(aaa[1]))\n",
    "print(eval(aaa[0]) == eval(aaa[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\captcha_demo\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "620it [00:15, 44.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/21325.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "795it [00:19, 44.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/72013.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:20, 44.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/92815.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1005it [00:24, 44.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/95905.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1190it [00:28, 44.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/6626.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1930it [00:45, 44.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/20814.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2060it [00:48, 44.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/3267.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2190it [00:51, 44.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/71218.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2330it [00:54, 44.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/16788.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2510it [00:58, 43.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/61510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2845it [01:06, 43.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/88604.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3190it [01:14, 43.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/54150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3205it [01:14, 43.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/49853.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3250it [01:15, 43.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/83498.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3260it [01:15, 42.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/65360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3375it [01:18, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/98488.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3390it [01:18, 43.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/92081.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3790it [01:28, 45.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/26328.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3915it [01:30, 43.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/63270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3925it [01:31, 40.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/43023.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5020it [01:56, 43.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/3687.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5165it [01:59, 44.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/55041.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5565it [02:08, 41.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/53708.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6395it [02:27, 44.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/84900.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6440it [02:28, 42.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/674.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6445it [02:28, 41.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/99929.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6530it [02:30, 43.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/70714.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6650it [02:33, 43.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/6572.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [02:41, 42.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/82426.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7445it [02:51, 43.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/38918.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7520it [02:53, 44.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/13678.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7885it [03:01, 44.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/75680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8130it [03:07, 44.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/33362.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8690it [03:20, 43.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/54579.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8810it [03:23, 44.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/22006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9000it [03:27, 44.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/58282.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9175it [03:31, 43.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/82493.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9425it [03:37, 44.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/35305.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9510it [03:39, 43.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/85879.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9720it [03:43, 43.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/88913.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9845it [03:46, 44.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/79071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [03:50, 44.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC :  0.9959\n",
      "letter ACC :  0.9347749938185115\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import string\n",
    "digits = string.digits\n",
    "operators = '+-*'\n",
    "characters = digits + operators + '()='\n",
    "characters+='a'#CTC用 占位符\n",
    "\n",
    "data_csv = pd.read_csv('G:/my_code/python/mathematical_expression_recognition/Mathematical_Expression_Recognition_train/train.csv')\n",
    "img_dirpath = data_csv['filename'].tolist()\n",
    "label = data_csv['label'].tolist()\n",
    "X_data, X_valid, y_data, y_valid = train_test_split(img_dirpath, label, test_size=10000, random_state=17)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=10000, random_state=17)\n",
    "\n",
    "def decode_label(out):\n",
    "    out_best = list(np.argmax(out[0, 2:], axis=1))  # get max index\n",
    "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
    "    outstr = ''\n",
    "    for i in out_best:\n",
    "        if i < len(letters):\n",
    "            outstr += letters[i]\n",
    "    return outstr\n",
    "\n",
    "def decode_label2(out):\n",
    "    out_best = list(np.argmax(out[0, 2:], axis=1))  # get max index\n",
    "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
    "    outstr = ''.join([characters[x] for x in out_best if x > -1 and x < 16])\n",
    "    return outstr\n",
    "\n",
    "model_best = get_model(img_w, img_h, num_classes, False)\n",
    "model_best.load_weights(\"best_weight.hdf5\")\n",
    "\n",
    "model_best2 = get_model2(width, height, n_class, n_len)\n",
    "model_best2.load_weights(\"7.model_gru_best2.h5\")\n",
    "\n",
    "model_best3 = get_model3(width, height, n_class, n_len)\n",
    "model_best3.load_weights(\"6.model_gru_best2_0.9833.h5\")\n",
    "\n",
    "total = 0\n",
    "acc = 0\n",
    "letter_total = 0\n",
    "letter_acc = 0\n",
    "\n",
    "result = defaultdict(str)\n",
    "\n",
    "for i, img_file in tqdm(enumerate(X_test)):\n",
    "    img = cv2.imread( rootpath+ img_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img_pred = img.astype(np.float32)\n",
    "    img_pred1 = cv2.resize(img_pred, (img_w, img_h))\n",
    "    img_pred1 = (img_pred1 / 255.0) * 2.0 - 1.0\n",
    "    img_pred1 = img_pred1.T\n",
    "    img_pred1 = np.expand_dims(img_pred1, axis=-1)\n",
    "    img_pred1 = np.expand_dims(img_pred1, axis=0)\n",
    "    net_out_value = model_best.predict(img_pred1)\n",
    "    pred_texts = decode_label(net_out_value)\n",
    "    try:\n",
    "        #如果算式从计算结果上就不对，使用模型2预测\n",
    "        tem_list = pred_texts.split('=')\n",
    "        if eval(tem_list[0]) != eval(tem_list[1]):\n",
    "            img_pred2 = cv2.resize(img_pred, (width, height))\n",
    "            img_pred2 = (img_pred2 / 255.0) * 2.0 - 1.0\n",
    "            img_pred2 = img_pred2.T\n",
    "            img_pred2 = np.expand_dims(img_pred2, axis=-1)\n",
    "            X = np.zeros((1, width, height, 1))\n",
    "            X[0] = img_pred2\n",
    "            net_out_value = model_best2.predict(X)\n",
    "            pred_texts = decode_label2(net_out_value)\n",
    "        \n",
    "        #如果算式从计算结果上就不对，使用模型3预测\n",
    "        tem_list = pred_texts.split('=')\n",
    "        if eval(tem_list[0]) != eval(tem_list[1]):\n",
    "            img_pred3 = cv2.resize(img_pred, (width, height))\n",
    "            img_pred3 = (img_pred3 / 255.0) * 2.0 - 1.0\n",
    "            img_pred3 = img_pred3.T\n",
    "            img_pred3 = np.expand_dims(img_pred3, axis=-1)\n",
    "            X = np.zeros((1, width, height, 1))\n",
    "            X[0] = img_pred3\n",
    "            net_out_value = model_best3.predict(X)\n",
    "            pred_texts = decode_label2(net_out_value)\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "#     tem_list = pred_texts.split('=')\n",
    "#     print(eval(tem_list[0]) == eval(tem_list[1]))\n",
    "    \n",
    "    for j in range(min(len(pred_texts), len(y_test[i]))):\n",
    "        if pred_texts[j] == y_test[i][j]:\n",
    "            letter_acc += 1\n",
    "    letter_total += max(len(pred_texts), len(label[i]))\n",
    "    \n",
    "    if pred_texts == y_test[i]:\n",
    "        acc += 1\n",
    "    else:\n",
    "        print(img_file)\n",
    "    total += 1\n",
    "\n",
    "print(\"ACC : \", acc / total)\n",
    "print(\"letter ACC : \", letter_acc / letter_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [03:45, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC :  0.9827\n",
      "letter ACC :  0.9330331846326613\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "acc = 0\n",
    "letter_total = 0\n",
    "letter_acc = 0\n",
    "for i, img_file in tqdm(enumerate(X_test)):\n",
    "    img = cv2.imread( rootpath+ img_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img_pred = img.astype(np.float32)\n",
    "    img_pred1 = cv2.resize(img_pred, (img_w, img_h))\n",
    "    img_pred1 = (img_pred1 / 255.0) * 2.0 - 1.0\n",
    "    img_pred1 = img_pred1.T\n",
    "    img_pred1 = np.expand_dims(img_pred1, axis=-1)\n",
    "    img_pred1 = np.expand_dims(img_pred1, axis=0)\n",
    "    net_out_value = model_best.predict(img_pred1)\n",
    "    pred_texts = decode_label(net_out_value)\n",
    "    \n",
    "    for j in range(min(len(pred_texts), len(y_test[i]))):\n",
    "        if pred_texts[j] == y_test[i][j]:\n",
    "            letter_acc += 1\n",
    "    letter_total += max(len(pred_texts), len(label[i]))\n",
    "    \n",
    "    if pred_texts == y_test[i]:\n",
    "        acc += 1\n",
    "    total += 1\n",
    "\n",
    "print(\"ACC : \", acc / total)\n",
    "print(\"letter ACC : \", letter_acc / letter_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-(8+8)=-9\n",
      "5-8+6=-9\n"
     ]
    }
   ],
   "source": [
    "img_file = 'train/62460.jpg'\n",
    "img = cv2.imread( rootpath+ img_file, cv2.IMREAD_GRAYSCALE)\n",
    "img_pred = img.astype(np.float32)\n",
    "img_pred1 = cv2.resize(img_pred, (img_w, img_h))\n",
    "img_pred1 = (img_pred1 / 255.0) * 2.0 - 1.0\n",
    "img_pred1 = img_pred1.T\n",
    "img_pred1 = np.expand_dims(img_pred1, axis=-1)\n",
    "img_pred1 = np.expand_dims(img_pred1, axis=0)\n",
    "net_out_value = model_best.predict(img_pred1)\n",
    "pred_texts = decode_label(net_out_value)\n",
    "print(pred_texts)\n",
    "\n",
    "img_pred2 = cv2.resize(img_pred, (width, height))\n",
    "img_pred2 = (img_pred2 / 255.0) * 2.0 - 1.0\n",
    "img_pred2 = img_pred2.T\n",
    "img_pred2 = np.expand_dims(img_pred2, axis=-1)\n",
    "X = np.zeros((1, width, height, 1))\n",
    "X[0] = img_pred2\n",
    "net_out_value = model_best2.predict(X)\n",
    "pred_texts = decode_label2(net_out_value)\n",
    "print(pred_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captcha_demo",
   "language": "python",
   "name": "captcha_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
